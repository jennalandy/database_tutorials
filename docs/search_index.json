[
["index.html", "Using Databases 1 Preface", " Using Databases 2020-04-28 1 Preface "],
["introduction.html", "2 Introduction", " 2 Introduction With the advent of large and remote data sources comes a need properly understand the methods for interacting with such data. The Cal Poly statistics department, at the current time, lacks a formal remote data course. This leaves it up to the discresion of professor to include such material in thier courses, and possibly leaves students to learn these essential skills outside of the classroom. The technical purpose of this book is to demostrate how to connect to, upload data to, and read data from the statistics department online dataset repository. All the datasets are stored in a relational database, meaning that they are stored in a standardized, tabular format. The tables are related according to specific columns, or keys. Additionally, they are stored in a remote server that can be accesses from any computer with an internet connection and the proper usernames and passwords. "],
["machine-setup.html", "3 Machine Setup 3.1 Linux - Ubuntu 3.2 Mac OS 3.3 Windows 3.4 Other Connection Options", " 3 Machine Setup The manual takes uses the OCDB driver/ connection string method to connnect to the Stats repository.These drivers are proprietary to the SQL service you are using, so they need to be installed for each server type you wish to connect to. Connection strings refer to the passwords and information needed to connect to the database, as well as the format that that information needs to be specified in. Connection strings are also specific to the database you are connecting to. For this example the driver and connection string can be found at the link below. Microsoft SQL Server Drivers can be found at: https://docs.microsoft.com/en-us/sql/connect/odbc/microsoft-odbc-driver-for-sql-server?view=sql-server-ver15 After downloading, the drivers can be installed by running the following commands in a terminal. 3.1 Linux - Ubuntu sudo su curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - #Download appropriate package for the OS version #Choose only ONE of the following, corresponding to your OS version #Ubuntu 16.04 curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list #Ubuntu 18.04 curl https://packages.microsoft.com/config/ubuntu/18.04/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list #Ubuntu 19.10 curl https://packages.microsoft.com/config/ubuntu/19.10/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list exit sudo apt-get update sudo ACCEPT_EULA=Y apt-get install msodbcsql17 # optional: for bcp and sqlcmd sudo ACCEPT_EULA=Y apt-get install mssql-tools echo &#39;export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;&#39; &gt;&gt; ~/.bash_profile echo &#39;export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;&#39; &gt;&gt; ~/.bashrc source ~/.bashrc # optional: for unixODBC development headers sudo apt-get install unixodbc-dev 3.2 Mac OS /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; brew tap microsoft/mssql-release https://github.com/Microsoft/homebrew-mssql-release brew update HOMEBREW_NO_ENV_FILTERING=1 ACCEPT_EULA=Y brew install msodbcsql17 mssql-tools 3.3 Windows download and open msodbcsql.msi file from: https://docs.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server?view=sql-server-ver15#download-for-windows 3.4 Other Connection Options Once drivers are installed, you can set a dsn (data source name) for the connection to the database using the ODBC/DSN manager for your system. This is OS-specific and while it will allow a single user to access the database more easily, it must be configured for every user who wishes to connect to the data source. Therefore, to more easily share code and to not have to mess with their behind-the-scenes settings, I use the connection string method from here further. "],
["connecting-to-a-database.html", "4 Connecting to a Database 4.1 Julia 4.2 SAS 4.3 R 4.4 Python 4.5 JSL", " 4 Connecting to a Database 4.1 Julia using ODBC # driver/connection string found at # https://docs.microsoft.com/en-us/sql/connect/odbc/microsoft-odbc-driver-for-sql-server?view=sql-server-ver15 #enter user information to be passed into the connection string database= begin print(&quot;Enter Database Name: &quot;) readline() end user= begin print(&quot;Enter Username: &quot;) readline() end crypt=Base.getpass(&quot;Enter Password&quot;) pass=read(crypt,String) # setting up database dsn = ODBC.DSN(&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=$database;UID=$user;PWD=$pass;&quot;) ODBC.disconnect() 4.2 SAS /*from proc sql directly*/ /*this is pretty convoluted*/ proc sql; connect to odbc as conn required=&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=ntsb;UID=ntsb;PWD=Cessna182&quot;; create table event as select * from connection to conn (select * from events) ; disconnect from conn; quit; /*by using a libname*/ libname conn2 odbc required =&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=ntsb;UID=ntsb;PWD=Cessna182&quot;; proc sql; create table event as select * from conn2.events ; quit; 4.3 R library(odbc) library(DBI) # note: if files are private, can replace with raw strings of database, uid, and pwd database = rstudioapi::showPrompt(&quot;Database name&quot;,&quot;Database name&quot;) uid = rstudioapi::showPrompt(&quot;Database username&quot;, &quot;Database username&quot;) pwd = rstudioapi::askForPassword(&quot;Database password&quot;) # open connection conn &lt;- dbConnect( odbc(), Driver = &quot;ODBC Driver 17 for SQL Server&quot;, Server = &quot;24.205.251.117&quot;, Database = database, UID = uid, PWD = pwd ) # close connection when done dbDisconnect(conn) 4.4 Python The driver used for Python may depend on your setup. import pyodbc driver = &quot;{ODBC Driver 17 for SQL Server}&quot; # PC Users # driver = &quot;/usr/local/lib/libmsodbcsql.17.dylib&quot; # Mac Users # note: if files are private, can replace with strings database = input(&quot;Database name: &quot;) username = input(&quot;Username: &quot;) password = getpass.getpass(prompt = &quot;Password: &quot;) # open connection conn = pyodbc.connect( &quot;;&quot;.join([ &quot;Driver=&quot;+driver, &quot;Address=24.205.251.117&quot;, &quot;Database=&quot;+database, &quot;UID=&quot;+username, &quot;PWD=&quot;+password ]) ) # get cursor cursor = conn.cursor() # close connection when done conn.close() 4.5 JSL opendatabaseconnection( &quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=ntsb;UID=ntsb;PWD=Cessna182&quot; ) "],
["writing-to-a-database.html", "5 Writing to a Database 5.1 Julia 5.2 R 5.3 Python 5.4 SAS", " 5 Writing to a Database 5.1 Julia using ODBC, CSV, JuliaDB, Query dsn = ODBC.DSN(&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=$database;UID=$user;PWD=$pass;&quot;) #= depending on your ODBC driver, you could do something as simple as ODBC.load(database, &quot;name of sql table&quot;, julia_table) some ODBC drivers/database systems don&#39;t support this however, including MS SQL Server so we must use an alternative method =# ## create the tables ODBC.execute!(dsn,&quot;&quot;&quot; create table projects (Class VARCHAR(10), id INT, StartDate INT, EndDate INT) &quot;&quot;&quot;) ODBC.execute!(dsn, &quot;create table users (Class VARCHAR(10), Fname VARCHAR(16), Lname VARCHAR(16), Email VARCHAR(36), Phone VARCHAR(9), Dept VARCHAR(10), id INT) &quot;) ## make a sql statement with &quot;blank&quot; values that we&#39;ll put in actual values into insertstmt=ODBC.prepare(dsn,&quot;insert into projects values(?,?,?,?)&quot;) ## now for each row in the rows of gridprojects, run the previous insert statemet, with the values for each row ## inserted into the previous &quot;blank rows&quot; ie those question marks for row in rows(gridprojects) ODBC.execute!(insertstmt,row) end ## make a sql statement with &quot;blank&quot; values that we&#39;ll put in actual values into insertstmt=ODBC.prepare(dsn,&quot;insert into users values(?,?,?,?,?,?,?)&quot;) ## now for each row in the rows of gridusers, run the previous insert statemet, with the values for each row ## inserted into the previous &quot;blank rows&quot; ie those question marks for row in rows(gridusers) ODBC.execute!(insertstmt,row) end # select top 50 rows from sample table, select as a julia DB indexed table. results=ODBC.query(dsn,&quot;select TOP 50 * from projects&quot;) |&gt; table #============================== Loading Data Bigger than Memory =========================================================# # ok so this isn&#39;t actually larger than memory, but it should work for any delimited text file of arbitray size ODBC.execute!(dsn,&quot;&quot;&quot;&quot; create table iris (Sepal_length Float, Sepal_width Float, Petal_length FLOAT, Petal_width FLOAT, Species VARCHAR(20) ) &quot;&quot;&quot;) insertstmt=ODBC.prepare(dsn,&quot;insert into iris values(?,?,?,?,?)&quot;) #================================== Utilizing the CSV package (more optimized)============================================# for row in CSV.Rows(&quot;iris.csv&quot;,skipto=2 ) ODBC.execute!(insertstmt,row) end #================================== In base Julia (less optimized)=========================================================# ODBC.execute!(dsn,&quot;&quot;&quot; create table iris2 (Sepal_length Float, Sepal_width Float, Petal_length FLOAT, Petal_width FLOAT, Species VARCHAR(20) ) &quot;&quot;&quot;) insertstmt=ODBC.prepare(dsn,&quot;insert into iris values(?,?,?,?,?)&quot;) ## open the file open(&quot;iris.csv&quot;) do f #put this readline in if you&#39;d like to skip the first row readline(f) #for the remaining lines, read in as a single string, break apart at the commas, then insert the rest for lines in readlines(f) rawline=map(String,split(lines, &quot;,&quot;)) ODBC.execute!(insertstmt,rawline) end end #========================================Bulk Insert ======================================================================# #= If you have bulk insert permissions you can do something like below to write data without reading it into memory Note, this is not tested, since I do not have bulk load permissions, so use at own risk more info can be found at https://docs.microsoft.com/en-us/sql/relational-databases/import-export/import-bulk-data-by-using-bulk-insert-or-openrowset-bulk-sql-server?view=sql-server-ver15#bulk-insert-statement =# #= ODBC.execute!(dsn,&quot;&quot;&quot; BULK INSERT iris FROM &#39;iris.csv&#39; &quot;&quot;&quot;) ODBC.execute!(dsn, &quot;&quot;&quot; INSERT INTO iris (Sepal_length, Sepal_width, Petal_length, Petal_width, Species) SELECT * FROM OPENROWSET ( BULK &#39;iris.csv&#39;) AS b ; &quot;&quot;&quot;) =# ODBC.disconnect!(dsn) 5.2 R 5.2.1 Simple Table: Iris # drop table from database, if it exists dbExecute(conn, &#39;drop table if exists iris;&#39;) # create new table from iris dataset dbWriteTable(conn, name = &quot;iris&quot;, value = iris) # make sure table exists in database dbListTables(conn, table_name = &quot;iris&quot;) # list fields the new table dbListFields(conn, name = &quot;iris&quot;) 5.2.2 Related Tables Connected by Keys: Bakery Files # load dataframes customers &lt;- read.csv(&#39;BAKERY/customers.csv&#39;, stringsAsFactors = FALSE) goods &lt;- read.csv(&#39;BAKERY/goods.csv&#39;, stringsAsFactors = FALSE) items &lt;- read.csv(&#39;BAKERY/items.csv&#39;, stringsAsFactors = FALSE) receipts &lt;- read.csv(&#39;BAKERY/receipts.csv&#39;, stringsAsFactors = FALSE) # clean Item column items$Item &lt;- trimws(items$Item) # can&#39;t drop a table if it is referenced by another table dbExecute(conn, &#39;drop table if exists items;&#39;) dbExecute(conn, &#39;drop table if exists goods;&#39;) dbExecute(conn, &#39;drop table if exists receipts;&#39;) dbExecute(conn, &#39;drop table if exists customers;&#39;) ## --- customers --- # create new table from customers dataset dbWriteTable(conn, name = &quot;customers&quot;, value = customers) # the column we want as a primary key must not be null, then we can add the constraint dbExecute(conn, &#39;alter table customers alter column Id int not null;&#39;) dbExecute(conn, &#39;alter table customers add primary key (Id);&#39;) # check key usage in this table dbGetQuery(conn, &quot;select * from information_schema.key_column_usage where TABLE_NAME = &#39;customers&#39;;&quot;) ## --- goods --- # create new table from goods dataset dbWriteTable(conn, name = &quot;goods&quot;, value = goods) # the column we want as a primary key must not be null, then we can add the constraint dbExecute(conn, &#39;alter table goods alter column Id varchar(20) not null;&#39;) dbExecute(conn, &#39;alter table goods add primary key (Id);&#39;) # check key usage in this table dbGetQuery(conn, &quot;select * from information_schema.key_column_usage where TABLE_NAME = &#39;goods&#39;;&quot;) ## --- receipts --- # create new table from receipts dataset dbWriteTable(conn, name = &quot;receipts&quot;, value = receipts) # the column we want as a primary key must not be null, then we can add the constraint dbExecute(conn, &#39;alter table receipts alter column ReceiptNumber int not null;&#39;) dbExecute(conn, &#39;alter table receipts add primary key (ReceiptNumber);&#39;) dbExecute(conn, &#39;alter table receipts alter column CustomerID int not null;&#39;) dbExecute(conn, &#39;alter table receipts add foreign key (CustomerID) references customers (Id);&#39;) # check key usage in this table dbGetQuery(conn, &quot;select * from information_schema.key_column_usage where TABLE_NAME = &#39;receipts&#39;;&quot;) ## --- items --- # create new table from items dataset dbWriteTable(conn, name = &quot;items&quot;, value = items) # the column we want as a primary key must not be null, then we can add the constraint dbExecute(conn, &#39;alter table items alter column Receipt int not null;&#39;) dbExecute(conn, &#39;alter table items alter column Ordinal int not null;&#39;) dbExecute(conn, &#39;alter table items add primary key (Receipt, Ordinal);&#39;) dbExecute(conn, &#39;alter table items add foreign key (Receipt) references receipts (ReceiptNumber);&#39;) dbExecute(conn, &#39;alter table items alter column Item varchar(20) not null;&#39;) dbExecute(conn, &#39;alter table items add foreign key (Item) references goods (Id);&#39;) # check key usage in this table dbGetQuery(conn, &quot;select * from information_schema.key_column_usage where TABLE_NAME = &#39;items&#39;;&quot;) 5.2.3 Strategy for Large Tables # drop table from database, if it exists dbExecute(conn, &#39;drop table if exists iris;&#39;) dbExecute(conn, paste( &quot;create table iris(&quot;, &quot;SepalLength decimal(5,2),&quot;, &quot;SepalWidth decimal(5,2),&quot;, &quot;PetalLength decimal(5,2),&quot;, &quot;PetalWidth decimal(5,2),&quot;, &quot;Species varchar(50)&quot;, &quot;);&quot;, sep = &#39; &#39; )) f &lt;- file(&quot;iris.csv&quot;, open = &quot;r&quot;) first = TRUE while (length(oneLine &lt;- readLines(f, n = 1)) &gt; 0) { if (first) { first = FALSE next } myLine &lt;- unlist((strsplit(oneLine, &quot;,&quot;))) insert_statement &lt;- paste( &quot;insert into iris(&quot;, &quot;SepalLength,&quot;, &quot;SepalWidth,&quot;, &quot;PetalLength,&quot;, &quot;PetalWidth,&quot;, &quot;Species&quot;, &quot;) values (&quot;, as.numeric(myLine[1]), &quot;,&quot;, as.numeric(myLine[2]), &quot;,&quot;, as.numeric(myLine[3]), &quot;,&quot;, as.numeric(myLine[4]),&quot;,&#39;&quot;, str_replace_all(myLine[5], &#39;\\&quot;&#39;,&#39;&#39;), &quot;&#39;);&quot; ) dbExecute(conn, insert_statement) } close(f) 5.3 Python 5.3.1 Simple Table: Iris # load in data with open(&#39;iris.csv&#39;) as file: iris_lines = file.readlines()[1:] # drop table if it already exists cursor.execute(&quot;drop table if exists iris;&quot;) # create new table cursor.execute(&quot; &quot;.join([ &quot;create table iris(&quot;, &quot;SepalLength decimal(5,2),&quot;, &quot;SepalWidth decimal(5,2),&quot;, &quot;PetalLength decimal(5,2),&quot;, &quot;PetalWidth decimal(5,2),&quot;, &quot;Species varchar(50)&quot; &quot;);&quot; ])) # single input: write one item to table line = iris_lines[0].split(&#39;,&#39;) cursor.execute( &quot; &quot;.join([ &quot;insert into iris(&quot;, &quot;SepalLength,&quot;, &quot;SepalWidth,&quot;, &quot;PetalLength,&quot;, &quot;PetalWidth,&quot;, &quot;Species&quot; &quot;)&quot; &quot;values(?, ?, ?, ?, ?)&quot;]), line[0], line[1], line[2], line[3], line[4].strip() ) # --OR-- # bulk input: write many items to table cursor.executemany( &quot; &quot;.join([ &quot;insert into iris(&quot;, &quot;SepalLength,&quot;, &quot;SepalWidth,&quot;, &quot;PetalLength,&quot;, &quot;PetalWidth,&quot;, &quot;Species&quot; &quot;)&quot; &quot;values(?, ?, ?, ?, ?)&quot;]), [line.split(&#39;,&#39;) for line in iris_lines[1:]] ) 5.3.2 Related Tables Connected by Keys: Bakery Files # drop tables if they already exists # can&#39;t drop a table if it is referenced by another table cursor.execute(&quot;drop table if exists items;&quot;) cursor.execute(&quot;drop table if exists goods;&quot;) # referenced by items cursor.execute(&quot;drop table if exists receipts;&quot;) # referenced by items cursor.execute(&quot;drop table if exists customers;&quot;) # referenced by receipts # create new tables cursor.execute(&quot; &quot;.join([ &quot;create table customers(&quot;, &quot;Id int,&quot;, &quot;LastName varchar(50),&quot;, &quot;FirstName varchar(50),&quot;, &quot;constraint customers_pk primary key (Id)&quot; &quot;);&quot; ])) cursor.execute(&quot; &quot;.join([ &quot;create table receipts(&quot;, &quot;ReceiptNumber int,&quot;, &quot;Date date,&quot;, &quot;CustomerId int,&quot;, &quot;constraint receipts_pk primary key (ReceiptNumber),&quot;, &quot;constraint receipts_customers_fk foreign key (CustomerId) references customers (Id)&quot; &quot;);&quot; ])) cursor.execute(&quot; &quot;.join([ &quot;create table goods(&quot;, &quot;Id varchar(50),&quot;, &quot;Flavor varchar(50),&quot;, &quot;Food varchar(50),&quot;, &quot;Price decimal(5,2),&quot;, &quot;constraint goods_pk primary key (Id)&quot; &quot;);&quot; ])) cursor.execute(&quot; &quot;.join([ &quot;create table items(&quot;, &quot;Receipt int,&quot;, &quot;Ordinal int,&quot;, &quot;Item varchar(50),&quot;, &quot;constraint items_pk primary key (Receipt, Ordinal),&quot;, &quot;constraint items_goods_fk foreign key (Item) references goods (Id),&quot;, &quot;constraint items_receipts_fk foreign key (Receipt) references receipts (ReceiptNumber)&quot; &quot;);&quot; ])) # load in data with open(&#39;BAKERY/customers.csv&#39;) as file: header = True # iterating through lines in this way doesn&#39;t read everything to memory at once # useful strategy for large files! for line in file: line = line.split(&#39;, &#39;) if header: header = False else: cursor.execute( &quot; &quot;.join([ &quot;insert into customers(&quot;, &quot;Id,&quot;, &quot;FirstName,&quot;, &quot;LastName&quot;, &quot;)&quot; &quot;values(?, ?, ?)&quot;]), line[0], line[1], line[2].strip() ) # load in data with open(&#39;BAKERY/receipts.csv&#39;) as file: header = True for line in file: line = line.split(&#39;, &#39;) if header: header = False else: # YYYYMMDD from DD-Mon-YYYY date = line[1].strip().replace(&quot;&#39;&quot;,&#39;&#39;) year = date.split(&#39;-&#39;)[2] day = date.split(&#39;-&#39;)[0] if len(day) == 1: day = &#39;0&#39;+day month = str(month_abbr_dict[date.split(&#39;-&#39;)[1]]) date2 = year+month+day cursor.execute( &quot; &quot;.join([ &quot;insert into receipts(&quot;, &quot;ReceiptNumber,&quot;, &quot;Date,&quot;, &quot;CustomerId&quot;, &quot;)&quot; &quot;values(?, ?, ?)&quot;]), line[0], date2, line[2].strip() ) # load in data with open(&#39;BAKERY/goods.csv&#39;) as file: header = True # iterating through lines in this way doesn&#39;t read everything to memory at once # useful strategy for large files! for line in file: line = line.strip().split(&#39;,&#39;) if header: header = False else: cursor.execute( &quot; &quot;.join([ &quot;insert into goods(&quot;, &quot;Id,&quot;, &quot;Flavor,&quot;, &quot;Food,&quot;, &quot;Price&quot; &quot;)&quot; &quot;values(?, ?, ?, ?)&quot;]), line[0], line[1], line[2], float(line[3]) ) # load in data with open(&#39;BAKERY/items.csv&#39;) as file: header = True # iterating through lines in this way doesn&#39;t read everything to memory at once # useful strategy for large files! for line in file: line = line.split(&#39;, &#39;) if header: header = False else: cursor.execute( &quot; &quot;.join([ &quot;insert into items(&quot;, &quot;Receipt,&quot;, &quot;Ordinal,&quot;, &quot;Item&quot;, &quot;)&quot; &quot;values(?, ?, ?)&quot;]), int(line[0]), int(line[1]), line[2].strip() ) 5.4 SAS /*Window Prompt Courtesy of SAS Documentation */ /** This code is for the SAS windowing environment only. **/ /** %WINDOW defines the prompt **/ %window info #5 @5 &#39;Please enter userid:&#39; #5 @26 id 8 attr=underline #7 @5 &#39;Please enter password:&#39; #7 @28 pass 8 attr=underline display=no; /** %DISPLAY invokes the prompt **/ %display info; /*by using a libname, much more straightforward*/ libname conn2 odbc required =&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=NickDb;UID=&amp;id;PWD=&amp;pass&quot;; /*from proc sql directly*/ /*this is pretty convoluted*/ proc sql; connect to odbc as conn required=&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=NickDb;UID=&amp;id;PWD=&amp;pass&quot;; create table event as select * from connection to conn (select * from events) ; disconnect from conn; quit; /*writing data from work directory to database*/ filename download url &quot;https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv&quot;; data iris; infile download delimiter = &quot;,&quot; firstobs=2; input var1-var4 species $; run; /*using the libname option again, turn on the bulkload for improved performance when loading large datasets */ /*since sas doesn&#39;t load everything into memory we can directly put sas datasets into the database! */ libname conn2 odbc required =&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=NickDb;UID=&amp;id;PWD=&amp;pass&quot; bulkload = YES; proc sql; create table conn3.iris as (select * from work.iris); quit; "],
["querying-a-database.html", "6 Querying a Database 6.1 Julia 6.2 R 6.3 Python 6.4 SAS", " 6 Querying a Database 6.1 Julia 6.2 R # get full dataframe of table data &lt;- dbReadTable(conn, name = &quot;iris&quot;) head(data) # get query results: returns dataframe species &lt;- dbGetQuery(conn, &#39;select distinct Species from iris&#39;) species 6.3 Python 6.3.1 Standard Python # execute a select statement cursor.execute(&quot;select * from iris&quot;) iris_out = cursor.fetchall() # output is a list of pyodbc.Row objects print(type(iris_out[1])) # can access by column names print(iris_out[1].SepalLength) # confirm it&#39;s the same as the input print(iris_lines[1].split(&#39;,&#39;)[0]) 6.3.2 Pandas import pandas as pd # returns a Pandas DataFrame iris_df_out = pd.read_sql(&quot;select * from iris&quot;, conn) print(type(iris_df_out)) 6.4 SAS "]
]
