[
["index.html", "Using Databases 1 Preface", " Using Databases Nick Padilla and Jenna Landy in collaboration with Hunter Glanz and Rebecca Ottesen 2020-05-14 1 Preface "],
["introduction.html", "2 Introduction", " 2 Introduction With the advent of large and remote data sources comes a need properly understand the methods for interacting with such data. The Cal Poly statistics department, at the current time, lacks a formal remote data course. This leaves it up to the discresion of professor to include such material in thier courses, and possibly leaves students to learn these essential skills outside of the classroom. The technical purpose of this book is to demostrate how to connect to, upload data to, and read data from the statistics department online dataset repository. All the datasets are stored in a relational database, meaning that they are stored in a standardized, tabular format. The tables are related according to specific columns, or keys. Additionally, they are stored in a remote server that can be accesses from any computer with an internet connection and the proper usernames and passwords. "],
["machine-setup.html", "3 Machine Setup 3.1 Linux - Ubuntu 3.2 Mac OS 3.3 Windows 3.4 Other Connection Options", " 3 Machine Setup The manual takes uses the OCDB driver / connection string method to connnect to the Stats repository. These drivers are proprietary to the SQL service you are using, so they need to be installed for each server type you wish to connect to. Connection strings refer to the passwords and information needed to connect to the database, as well as the format that that information needs to be specified in. Connection strings are also specific to the database you are connecting to. 3.1 Linux - Ubuntu sudo su curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - #Download appropriate package for the OS version #Choose only ONE of the following, corresponding to your OS version #Ubuntu 16.04 curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list #Ubuntu 18.04 curl https://packages.microsoft.com/config/ubuntu/18.04/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list #Ubuntu 19.10 curl https://packages.microsoft.com/config/ubuntu/19.10/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list exit sudo apt-get update sudo ACCEPT_EULA=Y apt-get install msodbcsql17 # optional: for bcp and sqlcmd sudo ACCEPT_EULA=Y apt-get install mssql-tools echo &#39;export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;&#39; &gt;&gt; ~/.bash_profile echo &#39;export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;&#39; &gt;&gt; ~/.bashrc source ~/.bashrc # optional: for unixODBC development headers sudo apt-get install unixodbc-dev 3.2 Mac OS /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; brew tap microsoft/mssql-release https://github.com/Microsoft/homebrew-mssql-release brew update HOMEBREW_NO_ENV_FILTERING=1 ACCEPT_EULA=Y brew install msodbcsql17 mssql-tools 3.3 Windows For Windows the driver and connection string can be found at: https://docs.microsoft.com/en-us/sql/connect/odbc/microsoft-odbc-driver-for-sql-server?view=sql-server-ver15#download-for-windows download and open the msodbcsql.msi file. 3.4 Other Connection Options Once drivers are installed, you can set a dsn (data source name) for the connection to the database using the ODBC/DSN manager for your system. This is OS-specific and while it will allow a single user to access the database more easily, it must be configured for every user who wishes to connect to the data source. Therefore, to more easily share code and to not have to mess with their behind-the-scenes settings, I use the connection string method from here further. "],
["connecting-to-a-database.html", "4 Connecting to a Database 4.1 Julia 4.2 SAS 4.3 R 4.4 Python 4.5 JSL", " 4 Connecting to a Database The first step to reading or writing to a database is the connection. Note that with Julia, R, and Python, we can ask the user to input the address, database name, username, and password each time the code is run. Asking the user to input credentials is good practice for scenarios when you’re sharing code, working on a shared computer, posting code publically on GitHub or elsewhere, or using sensitive data. However, if the files you’re working with are private and you feel comfortable, you can replace these with the raw strings of your credentials (e.x. database = &quot;database name&quot;). 4.1 Julia using ODBC # Get user credentials address = begin print(&quot;Enter Address: &quot;) readline() end database = begin print(&quot;Enter Database Name: &quot;) readline() end user = begin print(&quot;Enter Username: &quot;) readline() end crypt = Base.getpass(&quot;Enter Password&quot;) pass = read(crypt,String) # setting up database dsn = ODBC.DSN(&quot;Driver={ODBC Driver 17 for SQL Server};Address=$address;Database=$database;UID=$user;PWD=$pass;&quot;) # disconnect when you&#39;re done using this connection ODBC.disconnect() 4.2 SAS When using SAS, we can connect through proc sql or using a libname. We would recommend the latter, as the connection can be referenced throughout your sql file, as opposed to within one proc sql statement. Proc Sql /*from proc sql directly*/ proc sql; connect to odbc as conn required=&quot;Driver={ODBC Driver 17 for SQL Server};Address=&lt;address&gt;;Database=&lt;database name&gt;;UID=&lt;username&gt;;PWD=&lt;password&gt;&quot;; create table event as select * from connection to conn (select * from events) ; /*disconnect when you&#39;re done using this connection*/ disconnect from conn; quit; Libname /*by using a libname*/ libname conn2 odbc required =&quot;Driver={ODBC Driver 17 for SQL Server};Address=&lt;address&gt;;Database=&lt;database name&gt;;UID=&lt;username&gt;;PWD=&lt;password&gt;&quot;; proc sql; create table event as select * from conn2.events ; /*disconnect when you&#39;re done using this connection*/ disconnect from conn2; quit; 4.3 R Using R, we connect to the database using the odbc and DBI packages. library(odbc) library(DBI) address = rstudioapi::showPrompt(&quot;Address&quot;,&quot;Address&quot;) database = rstudioapi::showPrompt(&quot;Database name&quot;,&quot;Database name&quot;) uid = rstudioapi::showPrompt(&quot;Database username&quot;, &quot;Database username&quot;) pwd = rstudioapi::askForPassword(&quot;Database password&quot;) # open connection conn &lt;- dbConnect( odbc(), Driver = &quot;ODBC Driver 17 for SQL Server&quot;, Server = address, Database = database, UID = uid, PWD = pwd ) # disconnect when you&#39;re done using this connection dbDisconnect(conn) 4.4 Python The driver used in Python may depend on your setup. If you’re working on a PC, downloading the driver and connection from Microsoft directly should allow you to reference the driver name: driver = &quot;{ODBC Driver 17 for SQL Server}&quot; If you’re working on a Mac or Linux device, you cannot do this without further setup. It’s easiest to pass in the path to the dylib file, which should be installed to /usr/local/lib by default. With this setup, you will need to reference the driver like this: driver = &quot;/usr/local/lib/libmsodbcsql.17.dylib&quot; If copying and pasting the code below, switch which driver = line is commented depending on your operating system. import pyodbc driver = &quot;{ODBC Driver 17 for SQL Server}&quot; # PC Users # driver = &quot;/usr/local/lib/libmsodbcsql.17.dylib&quot; # Mac Users address = input(&quot;Address: &quot;) database = input(&quot;Database name: &quot;) username = input(&quot;Username: &quot;) password = getpass.getpass(prompt = &quot;Password: &quot;) # open connection conn = pyodbc.connect( &quot;;&quot;.join([ &quot;Driver=&quot;+driver, &quot;Address=&quot;+address, &quot;Database=&quot;+database, &quot;UID=&quot;+username, &quot;PWD=&quot;+password ]) ) # get cursor cursor = conn.cursor() # disconnect when you&#39;re done using this connection conn.close() 4.5 JSL opendatabaseconnection( &quot;Driver={ODBC Driver 17 for SQL Server};Address=&lt;address&gt;;Database=&lt;database&gt;;UID=&lt;username&gt;;PWD=&lt;password&gt;&quot; ) "],
["writing-to-a-database.html", "5 Writing to a Database 5.1 Julia 5.2 R 5.3 Python 5.4 SAS", " 5 Writing to a Database Once you are connected to a database, you can write tables to it (assuming you have write access). If you’re only using a database to access data, and aren’t writing to it, feel free to continue to the next chapter on querying a database. In the code blocks below, we assume you’ve already connected to your database and have named the connection as shown in the previous chapter on connecting to a database. 5.1 Julia Depending on your ODBC driver, you could write a table with a simple line of code: ODBC.load(database, &quot;name of sql table&quot;, julia_table) MS SQL Server along with other ODBC drivers/database systems don’t support this, so we must use an alternative method. Imports using ODBC, CSV, JuliaDB, Query Clear Up Workplace ODBC.execute!( dsn, &quot;&quot;&quot; drop table if exists goods; drop table if exists items; drop table if exists reciepts; drop table if exists customers; drop table if exists iris; drop table if exists iris2; &quot;&quot;&quot;, ) Create tables ODBC.execute!( dsn, &quot;&quot;&quot; create table projects (Class VARCHAR(10), id INT, StartDate INT, EndDate INT) &quot;&quot;&quot; ) ODBC.execute!( dsn, &quot;&quot;&quot; create table users (Class VARCHAR(10), Fname VARCHAR(16), Lname VARCHAR(16), Email VARCHAR(36), Phone VARCHAR(9), Dept VARCHAR(10), id INT) &quot;&quot;&quot; ) Insert values into tables First prepare an insert statement with blank values using ?s. Then, iterate through the rows of your data table. The line ODBC.execute!(insert_statement, row) will put the values from this row of data into the blank values of the insert statement, and then execute this complete SQL statement. # grid projects insert_statement = ODBC.prepare(dsn,&quot;insert into projects values(?,?,?,?)&quot;) for row in rows(gridprojects) ODBC.execute!(insert_statement, row) end # grid users insert_statement = ODBC.prepare(dsn,&quot;insert into users values(?,?,?,?,?,?,?)&quot;) for row in rows(gridusers) ODBC.execute!(insert_statement, row) end 5.1.1 Alternative method for big data The above method requires you to have the full dataset loaded into memory. But sometimes a data file is so large that it is inefficient to load everything at once and iterate through it to insert each row into a table. The method used here instead loads one row of data into memory at a time, and writes it to the SQL table before loading the next row. ODBC.execute!( dsn, &quot;&quot;&quot;&quot; create table iris (Sepal_length Float, Sepal_width Float, Petal_length FLOAT, Petal_width FLOAT, Species VARCHAR(20)) &quot;&quot;&quot; ) insert_statement = ODBC.prepare(dsn,&quot;insert into iris values(?,?,?,?,?)&quot;) open(&quot;iris.csv&quot;) do f readline(f) # skip the header row (remove this line if no header) # read one line at a time, write to SQL table, and repeat for lines in readlines(f) rawline = map(String, split(lines, &quot;,&quot;)) ODBC.execute!(insert_statement, rawline) end end The file can also be read using the CSV package. The code below would replace open(&quot;iris.csv&quot;) do f and everything following in the code chunk above . for row in CSV.Rows(&quot;iris.csv&quot;, skipto=2 ) ODBC.execute!(insert_statement, row) end 5.1.2 Bulk Insert If you have bulk insert permissions you can write data without reading it into memory. For more info, see bulk insert documentation. TODO: Test this. This code is not tested, since we do not have bulk load permissions. TODO: Explain the difference between these two options. ODBC.execute!( dsn, &quot;&quot;&quot; BULK INSERT iris FROM &#39;iris.csv&#39;; &quot;&quot;&quot; ) ODBC.execute!( dsn, &quot;&quot;&quot; INSERT INTO iris (Sepal_length, Sepal_width, Petal_length, Petal_width, Species) SELECT * FROM OPENROWSET ( BULK &#39;iris.csv&#39;) AS b; &quot;&quot;&quot; ) 5.2 R 5.2.1 Simple Table: Iris The first example is a basic one to illustrate how to create and fill a table. # drop table from database, if it exists dbExecute(conn, &#39;drop table if exists iris;&#39;) # make column names sql-compatable, can&#39;t have &quot;.&quot; in a name names(iris) &lt;- c( &#39;SepalLength&#39;,&#39;SepalWidth&#39;, &#39;PetalLength&#39;,&#39;PetalWidth&#39;, &#39;Species&#39; ) # create new table from iris dataset dbWriteTable(conn, name = &quot;iris&quot;, value = iris) # make sure table exists in database dbListTables(conn, table_name = &quot;iris&quot;) # list fields the new table dbListFields(conn, name = &quot;iris&quot;) 5.2.2 Related Tables Connected by Keys: Bakery Files This example uses related tables. The table sused here represent data that may be stored by a bakery. There is a list of customers who have customer Ids, a list of goods sold with good Ids, a list of receipts with a receipt Id as well as the Id of the customer who purchased the goods, and finally a list of items on eaach receipt. Load the data # load dataframes customers &lt;- read.csv(&#39;BAKERY/customers.csv&#39;, stringsAsFactors = FALSE) goods &lt;- read.csv(&#39;BAKERY/goods.csv&#39;, stringsAsFactors = FALSE) items &lt;- read.csv(&#39;BAKERY/items.csv&#39;, stringsAsFactors = FALSE) receipts &lt;- read.csv(&#39;BAKERY/receipts.csv&#39;, stringsAsFactors = FALSE) # clean Item column items$Item &lt;- trimws(items$Item) Drop tables if they already exist When tables are related, you can’t drop a table that’s referenced by another one. For example, the receipts table contains the customer Id of who made the purchase, referencing the customers table. This means that receipts must be dropped first. The relationships between tables will become more clear as we move into constructing tables. dbExecute(conn, &#39;drop table if exists items;&#39;) dbExecute(conn, &#39;drop table if exists goods;&#39;) dbExecute(conn, &#39;drop table if exists receipts;&#39;) dbExecute(conn, &#39;drop table if exists customers;&#39;) Create new tables We can now create new tables using the dbWriteTable function. When we create tables, each one should have a primary key, and some will also have a foreign key. The primary key is a column or multiple columns that serve as a unique identifier of each row of data. In the customers table, for instance, the primary key is the customer Id. This value cannot be empty. You’ll see that as we create each table, we first have to specify that the column is not null, and then add it as the primary key. A foreign key is a column in a table that references the primary key of another table. For instance, in receipts, we have a customer Id column telling us who made each purpose. In this case, customer Id is a foreign key in the receipts table referencing the primary key of the customers table. This value cannot be empty either, so you’ll see that again we specify the column is not null and then add it as a foreign key. The first example of this is for the receipts table. ## --- customers --- dbWriteTable(conn, name = &quot;customers&quot;, value = customers) dbExecute(conn, &#39;alter table customers alter column Id int not null;&#39;) dbExecute(conn, &#39;alter table customers add primary key (Id);&#39;) ## --- goods --- dbWriteTable(conn, name = &quot;goods&quot;, value = goods) dbExecute(conn, &#39;alter table goods alter column Id varchar(20) not null;&#39;) dbExecute(conn, &#39;alter table goods add primary key (Id);&#39;) ## --- receipts --- dbWriteTable(conn, name = &quot;receipts&quot;, value = receipts) dbExecute(conn, &#39;alter table receipts alter column ReceiptNumber int not null;&#39;) dbExecute(conn, &#39;alter table receipts add primary key (ReceiptNumber);&#39;) dbExecute(conn, &#39;alter table receipts alter column CustomerID int not null;&#39;) dbExecute(conn, &#39;alter table receipts add foreign key (CustomerID) references customers (Id);&#39;) ## --- items --- dbWriteTable(conn, name = &quot;items&quot;, value = items) dbExecute(conn, &#39;alter table items alter column Receipt int not null;&#39;) dbExecute(conn, &#39;alter table items alter column Ordinal int not null;&#39;) dbExecute(conn, &#39;alter table items add primary key (Receipt, Ordinal);&#39;) dbExecute(conn, &#39;alter table items add foreign key (Receipt) references receipts (ReceiptNumber);&#39;) dbExecute(conn, &#39;alter table items alter column Item varchar(20) not null;&#39;) dbExecute(conn, &#39;alter table items add foreign key (Item) references goods (Id);&#39;) Check key usage The following query will display information on the key usage within a table. We can use this to check that the keys were applied the way we were expecting. For the items table, receipt and ordianl together should serve as the primary key, receipt should be a foreign key referencing the receipts table, and item should be a foreign key referencing the goods table. # check key usage in this table dbGetQuery(conn, &quot;select * from information_schema.key_column_usage where TABLE_NAME = &#39;items&#39;;&quot;)[c(&#39;CONSTRAINT_NAME&#39;, &#39;COLUMN_NAME&#39;)] CONSTRAINT_NAME COLUMN_NAME 1 FK__items__Item__5006DFF2 Item 2 FK__items__Receipt__4F12BBB9 Receipt 3 PK__items__286FD81DF2E2854C Ordinal 4 PK__items__286FD81DF2E2854C Receipt 5.2.3 Alternative method for big data The above method requires you to have the full dataset loaded into memory. But sometimes a data file is so large that it is inefficient to load everything at once and iterate through it to insert each row into a table. The method used here instead loads one row of data into memory at a time, and writes it to the SQL table before loading the next row. It’s a bit more complex because we can’t use the simple dbWriteTable anymore. Instead, we define the table with a create table statement with dbExecute. To keep the code readable, we suggest using the paste function and using the same indentation you would in a sql file. For simplicity and lack of repetition, this example doesn’t use the four related datasets again. For information on defining primary and foreign keys in a create table statement, see the w3schools example for SQL primary key on SQL Server and for foreign keys. dbExecute(conn, &#39;drop table if exists iris;&#39;) dbExecute(conn, paste( &quot;create table iris(&quot;, &quot;SepalLength decimal(5,2),&quot;, &quot;SepalWidth decimal(5,2),&quot;, &quot;PetalLength decimal(5,2),&quot;, &quot;PetalWidth decimal(5,2),&quot;, &quot;Species varchar(50)&quot;, &quot;);&quot; )) f &lt;- file(&quot;iris.csv&quot;, open = &quot;r&quot;) first = TRUE # while the next line exists while (length(oneLine &lt;- readLines(f, n = 1)) &gt; 0) { # this skips the header row. delete this if there&#39;s no header if (first) { first = FALSE next } # separate values myLine &lt;- unlist(strsplit(oneLine, &quot;,&quot;)) # insert values insert_statement &lt;- paste( &quot;insert into iris(&quot;, &quot;SepalLength,&quot;, &quot;SepalWidth,&quot;, &quot;PetalLength,&quot;, &quot;PetalWidth,&quot;, &quot;Species&quot;, &quot;) values (&quot;, as.numeric(myLine[1]), &quot;,&quot;, as.numeric(myLine[2]), &quot;,&quot;, as.numeric(myLine[3]), &quot;,&quot;, as.numeric(myLine[4]),&quot;,&#39;&quot;, str_replace_all(myLine[5], &#39;\\&quot;&#39;,&#39;&#39;), &quot;&#39;);&quot; ) dbExecute(conn, insert_statement) } close(f) 5.3 Python In python, there’s no pretty function to create a table from a file or pandas DataFrame like there is in R. Here, we rely exclusively on the cursor’s execute method and raw sql strings. To keep the code readable, we suggest using the .join method on an empty string or space (&quot; &quot;) and using the same indentation you would in a sql file. Note that if you are using pandas, you can write data in the same way as shown here by iterating through the rows of the DataFrame as opposed to lines of a file. 5.3.1 Simple Table: Iris The first example is a basic one to illustrate how to create and fill a table. Load data # load in data with open(&#39;iris.csv&#39;) as file: iris_lines = file.readlines()[1:] Drop table if it exists, and create a new table # drop table if it already exists cursor.execute(&quot;drop table if exists iris;&quot;) # create new table cursor.execute(&quot; &quot;.join([ &quot;create table iris(&quot;, &quot;SepalLength decimal(5,2),&quot;, &quot;SepalWidth decimal(5,2),&quot;, &quot;PetalLength decimal(5,2),&quot;, &quot;PetalWidth decimal(5,2),&quot;, &quot;Species varchar(50)&quot; &quot;);&quot; ])) Insert values To insert values into a sql table, we have two options. This first strategy is beneficial because it doesn’t require you to load the full file into memory. This means that even if a dataset is very large, python can handle it. Here we only show using it to enter the first line of data, but this could be put inside of a for loop to iterate over all rows. # single input: write one item to table line = iris_lines[0].split(&#39;,&#39;) cursor.execute( &quot; &quot;.join([ &quot;insert into iris(&quot;, &quot;SepalLength,&quot;, &quot;SepalWidth,&quot;, &quot;PetalLength,&quot;, &quot;PetalWidth,&quot;, &quot;Species&quot; &quot;)&quot; &quot;values(?, ?, ?, ?, ?)&quot;]), line[0], line[1], line[2], line[3], line[4].strip() ) This second option is used to insert many rows of data into the table in one command. Using cursor.executemany, we can pass the same insert statement as above, but then a list of a list of values, where each inner list is 1 row of data. This is nice because it is less code. However, we prefer the first option because it is more consistent in that it will work for data tables of any size. # bulk input: write many items to table cursor.executemany( &quot; &quot;.join([ &quot;insert into iris(&quot;, &quot;SepalLength,&quot;, &quot;SepalWidth,&quot;, &quot;PetalLength,&quot;, &quot;PetalWidth,&quot;, &quot;Species&quot; &quot;)&quot; &quot;values(?, ?, ?, ?, ?)&quot;]), [line.split(&#39;,&#39;) for line in iris_lines[1:]] # [1:] because observation 0 was inserted above ) 5.3.2 Related Tables Connected by Keys: Bakery Files This example uses related tables. The tables used here represent data that may be stored by a bakery. There is a list of customers who have customer Ids, a list of goods sold with good Ids, a list of receipts with a receipt Id as well as the Id of the customer who purchased the goods, and finally a list of items on eaach receipt. Drop tables if they already exist When tables are related, you can’t drop a table that’s referenced by another one. For example, the receipts table contains the customer Id of who made the purchase, referencing the customers table. This means that receipts must be dropped first. The relationships between tables will become more clear as we move into constructing tables. cursor.execute(&quot;drop table if exists items;&quot;) cursor.execute(&quot;drop table if exists goods;&quot;) # referenced by items cursor.execute(&quot;drop table if exists receipts;&quot;) # referenced by items cursor.execute(&quot;drop table if exists customers;&quot;) # referenced by receipts Create new tables We can now create new tables using create table statements and cursor.execute. When we create tables, each one should have a primary key, and some will also have a foreign key. The primary key is a column or multiple columns that serve as a unique identifier of each row of data. In the customers table, for instance, the primary key is the customer Id. This value cannot be empty. This constraint is added automatically when we set the column(s) as the primary key. A foreign key is a column in a table that references the primary key of another table. For instance, in receipts, we have a customer Id column telling us who made each purpose. In this case, customer Id is a foreign key in the receipts table referencing the primary key of the customers table. This value cannot be empty either, and the constraint will automtically be applied when you set it as a foreign key. # create new tables cursor.execute(&quot; &quot;.join([ &quot;create table customers(&quot;, &quot;Id int,&quot;, &quot;LastName varchar(50),&quot;, &quot;FirstName varchar(50),&quot;, &quot;constraint customers_pk primary key (Id)&quot; &quot;);&quot; ])) cursor.execute(&quot; &quot;.join([ &quot;create table receipts(&quot;, &quot;ReceiptNumber int,&quot;, &quot;Date date,&quot;, &quot;CustomerId int,&quot;, &quot;constraint receipts_pk primary key (ReceiptNumber),&quot;, &quot;constraint receipts_customers_fk foreign key (CustomerId) references customers (Id)&quot; &quot;);&quot; ])) cursor.execute(&quot; &quot;.join([ &quot;create table goods(&quot;, &quot;Id varchar(50),&quot;, &quot;Flavor varchar(50),&quot;, &quot;Food varchar(50),&quot;, &quot;Price decimal(5,2),&quot;, &quot;constraint goods_pk primary key (Id)&quot; &quot;);&quot; ])) cursor.execute(&quot; &quot;.join([ &quot;create table items(&quot;, &quot;Receipt int,&quot;, &quot;Ordinal int,&quot;, &quot;Item varchar(50),&quot;, &quot;constraint items_pk primary key (Receipt, Ordinal),&quot;, &quot;constraint items_goods_fk foreign key (Item) references goods (Id),&quot;, &quot;constraint items_receipts_fk foreign key (Receipt) references receipts (ReceiptNumber)&quot; &quot;);&quot; ])) Load in data For each table, open file and insert values one line at a time. See the simple table example above for more details. with open(&#39;BAKERY/customers.csv&#39;) as file: header = True for line in file: line = line.split(&#39;, &#39;) if header: # dont write header row to database! header = False else: cursor.execute( &quot; &quot;.join([ &quot;insert into customers(&quot;, &quot;Id,&quot;, &quot;FirstName,&quot;, &quot;LastName&quot;, &quot;)&quot; &quot;values(?, ?, ?)&quot;]), line[0], line[1], line[2].strip() ) with open(&#39;BAKERY/receipts.csv&#39;) as file: header = True for line in file: line = line.split(&#39;, &#39;) if header: header = False else: # reformatting year: YYYYMMDD from DD-Mon-YYYY # sql likes the YYYYMMDD format date = line[1].strip().replace(&quot;&#39;&quot;,&#39;&#39;) year = date.split(&#39;-&#39;)[2] day = date.split(&#39;-&#39;)[0] if len(day) == 1: day = &#39;0&#39;+day month = str(month_abbr_dict[date.split(&#39;-&#39;)[1]]) date2 = year+month+day cursor.execute( &quot; &quot;.join([ &quot;insert into receipts(&quot;, &quot;ReceiptNumber,&quot;, &quot;Date,&quot;, &quot;CustomerId&quot;, &quot;)&quot; &quot;values(?, ?, ?)&quot;]), line[0], date2, line[2].strip() ) with open(&#39;BAKERY/goods.csv&#39;) as file: header = True for line in file: line = line.strip().split(&#39;,&#39;) if header: header = False else: cursor.execute( &quot; &quot;.join([ &quot;insert into goods(&quot;, &quot;Id,&quot;, &quot;Flavor,&quot;, &quot;Food,&quot;, &quot;Price&quot; &quot;)&quot; &quot;values(?, ?, ?, ?)&quot;]), line[0], line[1], line[2], float(line[3]) ) with open(&#39;BAKERY/items.csv&#39;) as file: header = True for line in file: line = line.split(&#39;, &#39;) if header: header = False else: cursor.execute( &quot; &quot;.join([ &quot;insert into items(&quot;, &quot;Receipt,&quot;, &quot;Ordinal,&quot;, &quot;Item&quot;, &quot;)&quot; &quot;values(?, ?, ?)&quot;]), int(line[0]), int(line[1]), line[2].strip() ) 5.4 SAS Security using SAS Here we are going to assign a new libname in order to show off some of the password protective features of SAA /*Window Prompt Courtesy of SAS Documentation */ /** This code is for the SAS windowing environment only. **/ /** %WINDOW defines the prompt **/ %window info #5 @5 &#39;Please enter userid:&#39; #5 @26 id 8 attr=underline #7 @5 &#39;Please enter password:&#39; #7 @28 pass 8 attr=underline display=no; /** %DISPLAY invokes the prompt **/ %display info; Connection using Saved inputs Make a connection using inputted user information. If you have bulkload permissions, you might want to enable that option in order to speed up file upload. libname conn2 odbc required =&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=NickDb;UID=&amp;id;PWD=&amp;pass&quot; /*bulkload = YES*/ ; URL Libname and Data Input Here we show off the url libname to download the iris csv file from the internet, and preprocess it using a data step. filename download url &quot;https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv&quot;; data iris; infile download delimiter = &quot;,&quot; firstobs=2; input var1-var4 species $; run; Writing Data Finally, we write this data to the database. Since sas processess data observation by observation, we don’t need to worry about memory constraints. proc sql; create table conn2.iris as (select * from work.iris); quit; "],
["querying-a-database.html", "6 Querying a Database 6.1 Julia 6.2 R 6.3 Python 6.4 SAS", " 6 Querying a Database Once you are connected to a database, you can query the tables that are there or the ones you have written. To review writing tables, see the previous chapter on writing to a database. In the code blocks below, we assume you’ve already connected to your database and have named the connection as shown in the third chapter on connecting to a database. In this chapter, we discuss the logistics of passing a query onto the database and reading the output using each language, rather than the basics of how to use sql. If you’re new to sql, please review the query syntax for MS SQL Server. Here are some references we recommend: SQL Keywords Reference by w3schools: where there are multiple options (i.e. MySQL or SQL Server / Oracle / MS Access) make sure you follow instructions for SQL Server SQL Tutorial by w3schools SQL Server Basics by sqlservertutorial 6.1 Julia Connect to Database dsn = ODBC.DSN(&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=$database;UID=$user;PWD=$pass;&quot;) Query and filter using server-side sql commands Note, lower case “query” returns a dataframe, as opposed to uppercase “Query” res=ODBC.query(dsn,&quot;&quot;&quot; select cyl, drat from mtcars where disp &gt; 200 &quot;&quot;&quot;) 6.1.1 Query database to select all rows, then filter/select rows in julia LINQ style res=@from i in ODBC.Query(dsn,&quot;select * from mtcars&quot;) begin @where i.disp &gt; 200 @select {Cylinder=i.cyl, Drat=i.drat} @collect table end dyplr/tidyverse style res = ODBC.query(dsn,&quot;select * from mtcars&quot;) |&gt; @filter( _.disp &gt; 200) |&gt; @select( :cyl, :drat) |&gt; DataFrame 6.2 R In R, you can choose to read a full table or query a subset with a sql query. Both options will return a data.frame. Read full table data &lt;- dbReadTable(conn, name = &quot;iris&quot;) head(data) Query a table species &lt;- dbGetQuery( conn, &#39;select distinct Species from iris&#39; ) species 6.3 Python 6.3.1 Standard Python In standard python, we pass a select statement to cursor.execute. To fetch the results as a list of rows, we use cursor.fetchall. Each row in this output is of the type pyodbc.Row, and with this data type we can access values by the column names of the table using dot notation. cursor.execute(&quot;select * from iris&quot;) iris_out = cursor.fetchall() print(type(iris_out[1])) first_sepal_length = iris_out[1].SepalLength 6.3.2 Pandas With pandas, we can use the read_sql function to query tables. This function returns the query results as a pandas DataFrame, which is frequently a lot easier to work with than the pyodbc.Row data type mentioned above. We recommend using pandas for this, and will continue to use pandas for the following chapters. import pandas as pd iris_df_out = pd.read_sql(&quot;select * from iris&quot;, conn) 6.4 SAS Query Using Libname Make the database connection. libname conn2 odbc required =&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=NickDb;UID=&amp;id;PWD=&amp;pass&quot;; Pull the rows that you need and disconnect from the database. proc sql; create table event as select * from conn2.events ; quit; libname conn2 clear; Query without libname While this means a libname is unecessary, the syntax is much more convoluted proc sql; connect to odbc as conn required=&quot;Driver={ODBC Driver 17 for SQL Server};Address=24.205.251.117;Database=NickDb;UID=&amp;id;PWD=&amp;pass&quot;; create table event as select * from connection to conn (select * from events) ; disconnect from conn; quit; "],
["web-api.html", "7 Web API 7.1 Julia 7.2 SAS", " 7 Web API Application programming interfaces, or API’s, loosely refer to inputs a user can submit to a computer program. If that sounds vague, don’t worry. The term API can cover a broad range of situations and in this section of the tutorial we are going to cover some of the basics of a more specific Web API. For statistical purposes, a web API is a method of integrating downloading data from a website into your code. Unlike SQL queries, web API requests are specific to the website you are attempting to download from to allow more flexibility. Web API’s are used by a variety of developers to request and retrieve data, and the tabular structure of returned by a SQL query may not be ideal. Web API’s utilize specific URL strings to locate the data that you wish to request, and typically give it to you in a format known as JSON. To address the first requirement, it’s ideal to do a quick web search and find the documentation of the API so that you understand the URL syntax. Assuming you have that correct and the website grants your request for data, the last step is to convert the JSON data to something a bit more usable for statistics. 7.1 Julia imports using HTTP, JSON, DataFrames, Query Enter the Correct URL and make the request urlcacurrent = &quot;https://covidtracking.com/api/v1/states/CA/current.json&quot; rawdata=HTTP.get(urlcurrent) Parse the JSON data #select the body of the API call, convert it into a string JSONdata = rawdata.body |&gt; String #parse JSON data, convert it into a DataFrame CACOVID = JSONdata |&gt; JSON.parse |&gt; DataFrame 7.2 SAS define a temporary file to read the JSON data into filename raw_json temp; use proc http to make the API call proc http url = &quot;https://covidtracking.com/api/v1/us/current.json&quot; method = &quot;GET&quot; out = raw_json QUERY=(&quot;parm1&quot; = &quot;val1&quot; &quot;parm2&quot; = &quot;val2&quot;); quit; This api uses the path segement of the url to specify parameters, but ifyou are using an an api that utilizes a query string use the query option as listed below, or append it directly to the url. If doing the latter, check the api documentation to see what delimiter is used between parameters. Parameters are typically specified in &quot;parm&quot; = &quot;val&quot; form. use the libname statement to convert the json file to a sas table libname Calif JSON fileref = raw_json; proc print data = Calif.alldata; run; "]
]
